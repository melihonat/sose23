{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1daf9f",
   "metadata": {},
   "source": [
    "# Exercise sheet 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78762dc7",
   "metadata": {},
   "source": [
    "In this second exercise sheet, we will apply some techniques we saw in the lectures about feature compression, clustering and generative models. We'll start by loading some of the libraries that we'll need.\n",
    "\n",
    "Note that comments in the coding exercise cells below just serve as hints and are not requirements for your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt to plot figures\n",
    "import matplotlib.pyplot as plt\n",
    "# numpy for array/matrix operations\n",
    "import numpy as np\n",
    "# loading the dataset loader function from sklearn\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# we set a seed variable for functions that use randomization (e.g. when shuffling data samples)\n",
    "# this way, we can have reproducible results even with randomization\n",
    "RANDOM_STATE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52d499",
   "metadata": {},
   "source": [
    "### 0.1) Dataset\n",
    "\n",
    "In this exercise sheet, we'll use the Wine dataset. From the description:\n",
    "\n",
    "\"The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine.\"\n",
    "\n",
    "The code below should be familiar from the 1st exercise sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c1700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the sklearn data object (python dictionary-style object)\n",
    "data = load_wine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a5a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unrelated but maybe helpful: show class type of data (might clarify how to work with it)\n",
    "print(\"Type of data: \", type(data))\n",
    "\n",
    "# Check number and name of classes\n",
    "print(\"Number of classes: \", len(np.unique(data['target'])))\n",
    "print(\"Class names: \", data.target_names)\n",
    "\n",
    "# features, target = data.data, data.target\n",
    "X_all, y_all = data.data, data.target\n",
    "# or with: features, target = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "print(\"Number of samples: \", X_all.shape[0])\n",
    "print(\"Number of features: \", X_all.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a457d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What kind of features?\n",
    "print(\"Feature names:\\n\")\n",
    "for idx, feature_name in enumerate(data.feature_names):\n",
    "    print(idx, feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ab3d3",
   "metadata": {},
   "source": [
    "## 1) Principal Component Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9200d",
   "metadata": {},
   "source": [
    "### 1.1) Data Visualization\n",
    "PCA can be used to help visualize your data by projecting high-dimensional feature spaces to lower-dimensional feature spaces. Let's try this here.\n",
    "\n",
    "#### (T1.1) Your Task: Use PCA to transform your data and project it to a 2-dimensional space. Visualize the result as a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aede05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for numpy (sklearn uses numpy's RNG)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "# import PCA class\n",
    "from sklearn.decomposition import PCA\n",
    "# import class used to apply z-normalization on your dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "### YOUR CODE HERE \n",
    "# instantiate the scaler\n",
    "\n",
    "# use the scaler's fit method to calculate mean and standard deviation of your train(!) set \n",
    "\n",
    "# apply transform method to standardize your data subsets\n",
    "\n",
    "# run PCA and transform your data\n",
    "\n",
    "\n",
    "# plot of two features (2D) after using PCA\n",
    "\n",
    "### YOUR CODE HERE END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ac281",
   "metadata": {},
   "source": [
    "### 1.2) Feature Compression\n",
    "\n",
    "PCA is also used for feature compression. This can e.g. improve the training/run time of your model while still reaching similar performances compared to using uncompressed feature vectors.\n",
    "\n",
    "#### (T1.2) Your task: Run PCA on your z-normalized train dataset. \n",
    "#### (T1.3) Your task: Determine the lowest number of principal components that result in explaining >80% of the variance in the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for numpy (sklearn uses numpy's RNG)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "# import PCA class\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "### YOUR CODE HERE\n",
    "# fit PCA\n",
    "\n",
    "\n",
    "# determine the lowest number of components necessary to reach >80% variance\n",
    "\n",
    "\n",
    "### YOUR CODE HERE END\n",
    "\n",
    "\n",
    "# print the number of principal components and explained variance\n",
    "print(\"Number of principal components that explain {:.2f} of the variance: {}\" \\\n",
    "      .format(explained_variance, component_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa3243",
   "metadata": {},
   "source": [
    "### 1.3) Experiments\n",
    "\n",
    "Let's now train a kNN classifier with and without PCA-based feature compression and compare the results.\n",
    "\n",
    "#### (T1.3) Your task:  Train and evaluate kNN (k=5) with 10-fold cross-validation, using the original given features. Then do the same with PCA-compressed features (using the number of PCA-components determined in T1.3 - note: alternatively use some random small number). Compare mean accuracy results. Hint: Feel free to copy&modify code from the first exercise sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffcfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE HERE END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00d382",
   "metadata": {},
   "source": [
    "## 2) Clustering: K-Means\n",
    "\n",
    "The k-means algorithm is an iterative algorithm that tries to partition the dataset into k pre-defined distinct non-overlapping clusters where each data point belongs to only one cluster. One of the applications of k-means is vector quantization. \n",
    "\n",
    "In this exercise, we'll use k-means to perform color quantization to an image. k-means will find a small number (=k) of representative colors within the given picture. Each pixel in the image yields a 3-dimensional pattern in the RGB color space. Using k-means we can cluster all the pixels of an image into k clusters and then assign each pixel the color represented by its nearest cluster center. Thereby, an image containing millions of colors can be compressed to an image containing k different colors only.\n",
    "\n",
    "#### (T2.1) Your task: Fit k-means with k=64 on the given image. Predict the nearest cluster center for all pixels in the image. Recreate the image and visualize it.\n",
    "#### (T2.2) Your task: Do the same with an image of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# for loading the image from sklearn\n",
    "from sklearn.datasets import load_sample_image\n",
    "# for shuffling input to k-means fit method (optional: faster if subset of all pixels are sampled instead of using full image)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "n_colors = 64\n",
    "\n",
    "# Load the Summer Palace photo\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "\n",
    "# Normalize color values to be in the range of [0-1] instead of [0-255]\n",
    "china = np.array(china, dtype=np.float64) / 255\n",
    "\n",
    "### YOUR CODE HERE \n",
    "# transform to a 2D numpy array of shape (n,3) with \"3\" containing RGB color intensities\n",
    "\n",
    "\n",
    "# Fitting the kmeans model (k=64), optionally do this only on a small sub-sample of the data if it takes too long with full image\n",
    "\n",
    "\n",
    "# Get labels for all points\n",
    "# Predicting color indices on the full image (k-means)\n",
    "\n",
    "\n",
    "# recreate the (compressed) image using labels and kmeans cluster centers\n",
    "\n",
    "\n",
    "# visualize the original image and the newly created image with 64 colors\n",
    "\n",
    "\n",
    "### YOUR CODE HERE END\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910524ff",
   "metadata": {},
   "source": [
    "## 3) Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f22e4",
   "metadata": {},
   "source": [
    "For this exercise, we'll use GMMs to separate background from foreground (here:flower) in a given image. Take a look at the image below.\n",
    "\n",
    "You'll need to estimate two mixtures of Gaussians to model the densities of the foreground and background pixels based on their color intensity. Then, apply the estimated models to the input image and segment the foreground and background regions.\n",
    "\n",
    "#### (T3.1) Your task: Write a method that selects all pixel values inside a specified bounding box (given by the coordinates of the top-left and bottom-right corners) that is containing the foreground region. Train a GMM for the foreground class using all pixels inside this bounding box. \n",
    "\n",
    "#### (T3.2) Your task: Train a GMM for the background class using all pixels OUTSIDE the bounding box used in T3.1.\n",
    "\n",
    "#### (T3.3) Your task: Compute the binary segmentation of the input image by making use of the two fitted GMMs. Then visualize this as a black&white image.\n",
    "\n",
    "\n",
    "Hint: Results are best if the bounding box mostly contains flower (=the foreground region). Comments below can serve as pointers for your own code (not a requirement). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc75309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image from sklearn database\n",
    "image = load_sample_image(\"flower.jpg\")\n",
    "\n",
    "# take a look at the image\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# load the image from sklearn database\n",
    "image = load_sample_image(\"flower.jpg\")\n",
    "\n",
    "### YOUR CODE HERE \n",
    "# function that returns mask for the bounding box\n",
    "# inverse: return mask for NOT(bounding box)\n",
    "\n",
    "\n",
    "# define a bounding box for the flower (x1,x2,y1,y2) with 0 origin of coordinates in upper left corner\n",
    "\n",
    "# get foreground (center flower) mask\n",
    "\n",
    "# take a look\n",
    "plt.imshow(fg)\n",
    "plt.show()\n",
    "\n",
    "# get background (not center flower) mask\n",
    "\n",
    "\n",
    "### YOUR CODE HERE END\n",
    "# take a look\n",
    "plt.imshow(bg)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93df396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "# Normalize color values to be in the range of [0-1] instead of [0-255]\n",
    "\n",
    "# transform all image variants to a 2D numpy array\n",
    "\n",
    "\n",
    "# select only elements that match the mask (=where the values are not zero)\n",
    "\n",
    "\n",
    "# make sure the number of selected elements matches the total number of elements in the image \n",
    "\n",
    "\n",
    "# train the foreground GMM (flower)\n",
    "\n",
    "\n",
    "# train the background GMM (rest)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# get likelihood scores from both models for each pixel in the image\n",
    "\n",
    "\n",
    "# determine which pixel belongs to which class (foreground/background)\n",
    "\n",
    "\n",
    "# visualize the result as a black/white image (0=fg=white), (1=bg=black)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE END\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829725e",
   "metadata": {},
   "source": [
    "# 4) Q&A (Bonus Points)      Due: Mo, 26.05.22, 23:59\n",
    "\n",
    "#### (T4) Your task: Answer the questions below and give explanations where required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc88be",
   "metadata": {},
   "source": [
    "4.1) What is the curse of dimensionality? \n",
    "\n",
    "4.2) What does PCA mean and what does it do (1 sentence)?\n",
    "\n",
    "4.3) What are the steps to calculate PCA? (roughly)?\n",
    "\n",
    "4.4) How is feature compression achieved with PCA?\n",
    "\n",
    "4.5) What is clustering in ML and what is it used for?\n",
    "\n",
    "4.6) What does the K in K-Means mean?\n",
    "\n",
    "4.7) What is the difference between discriminative and generative models? Give an example for each.\n",
    "\n",
    "4.9) Shortly explain the E- and the M- step in the EM-algorithm.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
